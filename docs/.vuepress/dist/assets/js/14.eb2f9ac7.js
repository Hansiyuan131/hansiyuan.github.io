(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{447:function(t,s,a){"use strict";a.r(s);var n=a(29),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,a=t._self._c||s;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"第一个scrapy网络爬虫"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第一个scrapy网络爬虫"}},[t._v("#")]),t._v(" 第一个Scrapy网络爬虫")]),t._v(" "),a("h2",{attrs:{id:"scrapy-的安装"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#scrapy-的安装"}},[t._v("#")]),t._v(" Scrapy 的安装")]),t._v(" "),a("p",[t._v("我这里使用的是Anaconda3")]),t._v(" "),a("ol",[a("li",[t._v("进入到当前项目的运行环境")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("activate python_crawler\n")])])]),a("ol",{attrs:{start:"2"}},[a("li",[t._v("执行安装命令")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("conda install scrapy\n")])])]),t._v(" "),a("ol",{attrs:{start:"3"}},[a("li",[t._v("验证安装")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" scrapy\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("version_info"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("hr"),t._v(" "),a("h2",{attrs:{id:"scrapy-新建项目"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#scrapy-新建项目"}},[t._v("#")]),t._v(" Scrapy 新建项目")]),t._v(" "),a("ol",[a("li",[t._v("打开Pycharm终端\n"),a("img",{attrs:{src:"/%E7%AC%AC%E4%B8%80%E4%B8%AAScrapy%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/B-1.png",alt:""}})]),t._v(" "),a("li",[t._v("执行命令，生成一个Scrapy项目")])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v("scrapy startproject 项目名\n")])])]),a("ol",{attrs:{start:"3"}},[a("li",[t._v("生成项目目录")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[t._v("scrapy "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("cfg  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 它是 Scrapy 项目的配置文件，其内定义了项目的配置文件路径 、 部署相关信息等内容 。")]),t._v("\nproject"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("\n\t一init一 "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" py\n\titems"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 它定义爬取结果(item)数据结构")]),t._v("\n\tpipelines"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 它定义项目管道的实现，它的主要任务是清洗、验证和存储数据。")]),t._v("\n\tsettings"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 项目的全局配置文件。")]),t._v("\n\tmiddlewares "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 它定义爬虫中间件和下载器中间件的实现。")]),t._v("\n\tspiders"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("/")]),t._v("   "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#其内包含一个个爬虫的实现，每个爬虫都有一个文件 。")]),t._v("\n\t\tinit "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py\n\t\tspiderl"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v(" py\n\t\tspider2 "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("py\n")])])]),a("hr"),t._v(" "),a("h2",{attrs:{id:"修改-settings"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#修改-settings"}},[t._v("#")]),t._v(" 修改 settings")]),t._v(" "),a("ol",[a("li",[t._v("打开"),a("code",[t._v("settings")]),t._v("文件，找到"),a("code",[t._v("USER_AGENT")])])]),t._v(" "),a("p",[a("img",{attrs:{src:"/%E7%AC%AC%E4%B8%80%E4%B8%AAScrapy%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/B-3.png",alt:""}})]),t._v(" "),a("ol",{attrs:{start:"2"}},[a("li",[t._v("打开浏览器任意页面，我这里打开的百度,找到"),a("code",[t._v("User-Agent")]),t._v("将其复制到"),a("code",[t._v("settings")]),t._v("的"),a("code",[t._v("USER_AGENT")]),t._v("下")])]),t._v(" "),a("p",[a("img",{attrs:{src:"/%E7%AC%AC%E4%B8%80%E4%B8%AAScrapy%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/B-2.png",alt:""}}),t._v(" "),a("img",{attrs:{src:"/%E7%AC%AC%E4%B8%80%E4%B8%AAScrapy%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/B-4.png",alt:""}})]),t._v(" "),a("hr"),t._v(" "),a("h2",{attrs:{id:"创建-spider-爬虫"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#创建-spider-爬虫"}},[t._v("#")]),t._v(" 创建 Spider (爬虫)")]),t._v(" "),a("p",[t._v("Spider组件解决了以下问题：")]),t._v(" "),a("ul",[a("li",[t._v("爬虫从哪个或哪些页面开始爬取。")]),t._v(" "),a("li",[t._v("对于一个已下载的页面，提取其中的哪些数据。")]),t._v(" "),a("li",[t._v("爬取完当前页面后，接下来爬取哪个或哪些页面。")])]),t._v(" "),a("ol",[a("li",[t._v("在Spider文件夹下新建"),a("code",[t._v("toscrape_spiders.py")]),t._v("文件   当然你也可以通过命令创建，这里就不多说了。")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v("  scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spiders "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Spider\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v("  scrapy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Request\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("toscrape_spiders")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'toscrape'")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 爬虫名字  唯一 必须")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# allowed_domains = ['books.toscrape.com']  # 过滤掉不是这个域名的链接请求")]),t._v("\n    start_urls "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://books.toscrape.com/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" \n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 它包含了 Spider 在启动时爬取的 url 列表，初始请求是由它来定义的 。")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("parse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 默认情况下，被调用时 start_urls 里面的链接构成的请求完成下载执行后，返回的响应就会作为唯一的参数传递给这个函数 。 该方法负责解析返回的响应、提取数据或者进一步生成要处理的请求")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("pass")]),t._v("\n\n")])])]),a("hr"),t._v(" "),a("h2",{attrs:{id:"创建-item"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#创建-item"}},[t._v("#")]),t._v(" 创建 Item")]),t._v(" "),a("blockquote",[a("p",[t._v("创建 Item 需要继承 scrapy.Item 类，并且定义类型为 scrapy.Field 的字段。")])]),t._v(" "),a("p",[t._v("代码如下")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" scrapy\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ToscrapeItem")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Field"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 书籍的名称")]),t._v("\n    price "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Field"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 价格")]),t._v("\n    url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Field"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 链接地址")]),t._v("\n    content "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Field"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 书籍简介")]),t._v("\n\n\n")])])]),a("hr"),t._v(" "),a("h2",{attrs:{id:"解析-response"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#解析-response"}},[t._v("#")]),t._v(" 解析 Response")]),t._v(" "),a("blockquote",[a("p",[t._v("parse （）方法的参数 resposne 是 start_urls 里面的链接爬取后的结果 。 所以在parse （）方法>中，我们可以直接对 response 变量包含的内容进行解析，比如浏览请求结果的网页源代码，或者>进一步分析源代码内容，或者找出结果中的链接而得到下一个请求。")])]),t._v(" "),a("p",[a("strong",[t._v("分析网页结构")]),t._v("\n我们使用谷歌开发者工具可以看到，书籍存放在"),a("code",[t._v("ol")]),t._v("列表中，每一个"),a("code",[t._v("li")]),t._v("标签下存放一本书的信息\n"),a("img",{attrs:{src:"/%E7%AC%AC%E4%B8%80%E4%B8%AAScrapy%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/B-5.png",alt:""}})]),t._v(" "),a("p",[t._v("我们仔细看一下"),a("code",[t._v("li")]),t._v("标签下的有些什么东西，你可以清晰的看到书籍名称存放在"),a("code",[t._v("h3")]),t._v("标签下的"),a("code",[t._v("a")]),t._v("标签中，书籍价格存放在"),a("code",[t._v("class=”product_price“")]),t._v("的"),a("code",[t._v("div")]),t._v("标签下的"),a("code",[t._v("p")]),t._v("标签中............\n"),a("img",{attrs:{src:"/%E7%AC%AC%E4%B8%80%E4%B8%AAScrapy%E7%BD%91%E7%BB%9C%E7%88%AC%E8%99%AB/B-6.png",alt:""}})]),t._v(" "),a("p",[t._v("那么我们先找出所有的 "),a("code",[t._v("li")]),t._v("标签 ，然后提取每一个 "),a("code",[t._v("li")]),t._v("标签 中的内容 。我们使用XPath选择器提取数据。")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spiders "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Spider\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scrapy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Request\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" toscrape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ToscrapeItem\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("toscrape_spiders")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'toscrape'")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# allowed_domains = ['quotes.toscrape.com']")]),t._v("\n    start_urls "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://quotes.toscrape.com/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("parse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        all_li "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('".//ol/li"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" li "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" all_li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('".//article/h3/a/text()"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            price "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"article/div[last()]/p[@class='price_color']/text()\"")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            main_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"article/div[@class='image_container']/a/@href\"")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            main_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://books.toscrape.com/catalogue/"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" main_url\n\n")])])]),a("hr"),t._v(" "),a("h2",{attrs:{id:"使用-item"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#使用-item"}},[t._v("#")]),t._v(" 使用 Item")]),t._v(" "),a("blockquote",[a("p",[t._v("Item 可以理解为一个字典，不过在声明的时候需要实例化。 然后依次用刚才解析的结果赋值 Item 的每一个字段， 最后将 Item 返回即可 。")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spiders "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Spider\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scrapy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Request\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" toscrape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ToscrapeItem\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("toscrape_spiders")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'toscrape'")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# allowed_domains = ['quotes.toscrape.com']")]),t._v("\n    start_urls "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://quotes.toscrape.com/'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("parse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        all_li "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('".//ol/li"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        item "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ToscrapeItem"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" li "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" all_li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('".//article/h3/a/text()"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            price "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"article/div[last()]/p[@class='price_color']/text()\"")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            main_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"article/div[@class='image_container']/a/@href\"")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            main_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://books.toscrape.com/catalogue/"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" main_url\n            item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" name  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 书籍名称")]),t._v("\n            item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"price"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" price  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 价格")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" item\n")])])]),a("hr"),t._v(" "),a("h2",{attrs:{id:"后续-request"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#后续-request"}},[t._v("#")]),t._v(" 后续 Request")]),t._v(" "),a("blockquote",[a("p",[t._v("我们该怎样抓取下一页内容呢???  怎么爬取详情页数据呢???\n这就需要我们从当前页面中找到信息来生成下一个请求，然后在下一个请求的页面里找到信息再构造再下一个请求 。 这样循环往复迭代，从而实现整站的爬取。")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scrapy"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("spiders "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Spider\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scrapy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" Request\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" re\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" toscrape"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("items "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" ToscrapeItem\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("toscrape_spiders")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("Spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'toscrape'")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# start_urls = ['http://books.toscrape.com/'] 第一页爬取不到 使用下边链接")]),t._v("\n    start_urls "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("'http://books.toscrape.com/catalogue/page-1.html'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("parse")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        all_li "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('".//ol/li"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        item "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" ToscrapeItem"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" li "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("in")]),t._v(" all_li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('".//article/h3/a/text()"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            price "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"article/div[last()]/p[@class='price_color']/text()\"")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            main_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" li"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"article/div[@class='image_container']/a/@href\"")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            main_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://books.toscrape.com/catalogue/"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" main_url\n            item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"name"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" name  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 书籍名称")]),t._v("\n            item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"price"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" price  "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 价格")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 发送访问详细页的请求")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" Request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("main_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" callback"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse_content"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" meta"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"myitem"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        next_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v("\"//li[@class='next']/a/@href\"")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" next_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            next_url "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"http://books.toscrape.com/catalogue/page-"')]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" re"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sub"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\D"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('""')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" next_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('".html"')]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" Request"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("next_url"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" callback"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("parse"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n       \n\t "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 提取并解析详细页的数据")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("parse_content")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        content "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("xpath"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"//article/p/text()"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("extract_first"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        item "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" response"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("meta"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"myitem"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"content"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" content\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("yield")]),t._v(" item\n")])])]),a("hr"),t._v(" "),a("h2",{attrs:{id:"运行爬虫"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#运行爬虫"}},[t._v("#")]),t._v(" 运行爬虫")]),t._v(" "),a("p",[t._v("在"),a("code",[t._v("scrapy.cfg")]),t._v("同目录下创建"),a("code",[t._v("start.py")]),t._v("文件")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scrapy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" cmdline\n\ncmdline"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("execute"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"scrapy crawl toscrape"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("hr"),t._v(" "),a("h2",{attrs:{id:"保存到文件"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#保存到文件"}},[t._v("#")]),t._v(" 保存到文件")]),t._v(" "),a("blockquote",[a("p",[t._v("可保存文件类型 'json', 'jsonlines', 'jl', 'csv', 'xml', 'marshal', 'pickle'")])]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("from")]),t._v(" scrapy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" cmdline\n\ncmdline"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("execute"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"scrapy crawl toscrape -o toscrape.csv"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("hr"),t._v(" "),a("h2",{attrs:{id:"使用-item-pipeline"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#使用-item-pipeline"}},[t._v("#")]),t._v(" 使用 Item Pipeline")]),t._v(" "),a("div",{staticClass:"language-python extra-class"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" pymongo\n\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ToscrapePipeline")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("object")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("open_spider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 连接MongoDb数据库服务器")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("db_client "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" pymongo"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("MongoClient"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("name "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("==")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"toscrape"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 指定操作的数据库")]),t._v("\n            self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("db "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("db_client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"toscrape"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 指定集合（类似MYSQL中的表）")]),t._v("\n            self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("db_collection "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("db"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"books"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" item\n\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("process_item")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("db_collection"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("insert_one"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[t._v("dict")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("item"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n        "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" item\n\n    "),a("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# 爬虫全部完成后执行一次（收尾工作）")]),t._v("\n    "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("def")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[t._v("close_spider")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" spider"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(":")]),t._v("\n        self"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("db_client"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("close"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),a("hr")])}),[],!1,null,null,null);s.default=e.exports}}]);